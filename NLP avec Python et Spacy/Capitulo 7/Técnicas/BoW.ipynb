{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots avec une frequence de 3 ou 4: \n",
      "des: 3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "text = \"L'analyse de texte est une composante essentielle de traitement du langage naturel. Elle permet d'extraire des informations, d'identifier des tendances et de comprendre le contexte sémantique. L'analyse de sentiment, la reconnaissance d'entités nommées et l'extraction de mots-clés son quelques-unes des applications de cette discipline\"\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "freq_dist = FreqDist(tokens)\n",
    "print(\"Mots avec une frequence de 3 ou 4: \")\n",
    "for word,frequency in freq_dist.items():\n",
    "    if frequency in [3,4]:\n",
    "        print(f\"{word}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solo muestra \"des:3\" cuando en realidad hay varias palabras que se repiten más veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots avec une frequence de 3 ou 4: \n",
      "d': 3\n",
      "des: 3\n",
      "et: 4\n",
      "le: 3\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "text = \"L'analyse de texte est une composante essentielle de traitement du langage naturel. Elle permet d'extraire des informations, d'identifier des tendances et de comprendre le contexte sémantique. L'analyse de sentiment, la reconnaissance d'entités nommées et l'extraction de mots-clés son quelques-unes des applications de cette discipline\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "freq_dist = {token.text: text.count(token.text) for token in doc}\n",
    "print(\"Mots avec une frequence de 3 ou 4: \")\n",
    "for word,frequency in freq_dist.items():\n",
    "    if frequency in [3,4]:\n",
    "        print(f\"{word}: {frequency}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
