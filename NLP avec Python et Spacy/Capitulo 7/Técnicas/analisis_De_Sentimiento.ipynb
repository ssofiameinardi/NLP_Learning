{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextCategorizer.update() got an unexpected keyword argument 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m texte, sentiment \u001b[38;5;129;01min\u001b[39;00m corpus:\n\u001b[32m     24\u001b[39m     exemple = Example.from_dict(nlp.make_doc(texte), {\u001b[33m\"\u001b[39m\u001b[33mcats\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mPOSITIF\u001b[39m\u001b[33m\"\u001b[39m: sentiment == \u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNEGATIF\u001b[39m\u001b[33m\"\u001b[39m: sentiment == \u001b[32m0\u001b[39m}})\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43mtextcat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexemple\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m#Otro ejemplo\u001b[39;00m\n\u001b[32m     29\u001b[39m nouveau_texte = \u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m\u001b[33mest un excellent produit, je le recommande vivement!\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: TextCategorizer.update() got an unexpected keyword argument 'dropout'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.add_pipe(\"textcat\", last=True)\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "\n",
    "corpus = [\n",
    "    (\"J'aime vraiment ce produit. Il est fantastique!\",1),\n",
    "    (\"C'est un peu décevant. Je m'attendais à mieux.\", 0),\n",
    "    (\"Le service clientèle est exceptionnel. Très satisfait.\", 1),\n",
    "    (\"Je ne recommanderais pas ce produit. Très mécontent\", 0)\n",
    "]\n",
    "\n",
    "textcat = nlp.get_pipe('textcat')\n",
    "textcat.add_label(\"POSITIF\")\n",
    "textcat.add_label(\"NEGATIF\")\n",
    "\n",
    "for texte, sentiment in corpus:\n",
    "    exemple = Example.from_dict(nlp.make_doc(texte), {\"cats\": {\"POSITIF\": sentiment == 1, \"NEGATIF\": sentiment == 0}})\n",
    "    textcat.update([exemple], dropout = 0.5)\n",
    "    \n",
    "\n",
    "#Otro ejemplo\n",
    "nouveau_texte = \"C'est un excellent produit, je le recommande vivement!\"\n",
    "\n",
    "doc = nlp(nouveau_texte)\n",
    "\n",
    "prediction = doc.cats\n",
    "\n",
    "print(\"Prédiction de sentiment: \")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente la versión 3.x de Spacy ya no soporta el textcat.update, como antes sí lo hacía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     19\u001b[39m ensemble_test = documents[seuil:]\n\u001b[32m     21\u001b[39m sentiment_analyzer = SentimentAnalyzer()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m classificateur = \u001b[43msentiment_analyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNaiveBayesClassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensemble_entrainement\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\sentiment\\sentiment_analyzer.py:179\u001b[39m, in \u001b[36mSentimentAnalyzer.train\u001b[39m\u001b[34m(self, trainer, training_set, save_classifier, **kwargs)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[33;03mTrain classifier on the training set, optionally saving the output in the\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[33;03mfile specified by `save_classifier`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m \u001b[33;03m:rtype:\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining classifier\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[38;5;28mself\u001b[39m.classifier = \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_classifier:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.save_file(\u001b[38;5;28mself\u001b[39m.classifier, save_classifier)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\classify\\naivebayes.py:212\u001b[39m, in \u001b[36mNaiveBayesClassifier.train\u001b[39m\u001b[34m(cls, labeled_featuresets, estimator)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m featureset, label \u001b[38;5;129;01min\u001b[39;00m labeled_featuresets:\n\u001b[32m    211\u001b[39m     label_freqdist[label] += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m fname, fval \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfeatureset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m():\n\u001b[32m    213\u001b[39m         \u001b[38;5;66;03m# Increment freq(fval|label, fname)\u001b[39;00m\n\u001b[32m    214\u001b[39m         feature_freqdist[label, fname][fval] += \u001b[32m1\u001b[39m\n\u001b[32m    215\u001b[39m         \u001b[38;5;66;03m# Record that fname can take the value fval.\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import mark_negation\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "corpus = [\n",
    "    (\"J'aime vraiment ce produit. Il est fantastique!\",1),\n",
    "    (\"C'est un peu décevant. Je m'attendais à mieux.\", 0),\n",
    "    (\"Le service clientèle est exceptionnel. Très satisfait.\", 1),\n",
    "    (\"Je ne recommanderais pas ce produit. Très mécontent\", 0)\n",
    "]\n",
    "\n",
    "documents = [(mark_negation(nltk.word_tokenize(texte)), sentiment) for texte,sentiment in corpus]\n",
    "\n",
    "#Division del corpus en pequeños conjuntos de entrenamiento y testeo\n",
    "seuil = int(0.8*len(documents))\n",
    "ensemble_entrainement = documents[:seuil]\n",
    "ensemble_test = documents[seuil:]\n",
    "\n",
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "classificateur = sentiment_analyzer.train(NaiveBayesClassifier.train, ensemble_entrainement)\n",
    "\n",
    "#Testeo con un nuevo texto\n",
    "nouveau_texte = \"C'est un excellent produit, je le recommande vivement!\"\n",
    "tokens_nouveau_texte = mark_negation(nltk.word_tokenize(nouveau_texte))\n",
    "sentiment_predi = classificateur.classify(dict([token, True] for token in tokens_nouveau_texte))\n",
    "\n",
    "#Muestra de la predicción\n",
    "print(\"Prediccion de sentimiento: \")\n",
    "print(\"Sentiment POSITIF\" if sentiment_predi == 1 else \"Sentiment NEGATIF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tampoco está funcionando.Aparece el error <<AttributeError: 'list' object has no attribut 'items'>> en la linea donde se define al classificateur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
