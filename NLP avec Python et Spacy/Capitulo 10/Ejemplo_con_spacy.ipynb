{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textes = [\n",
    "    \"Bonjour, comment ca va aujord'hui?\",\n",
    "    \"Hello, how are you today?\",\n",
    "    \"Hallo, wie geht es dir heute?\",\n",
    "    \"Hola, como estas hoy?\",\n",
    "    \"Ciao, come stai oggi?\",\n",
    "    \"Saluton, kiel vi fartas hodiaŭ?\",\n",
    "    \"Hej, hur mår du idag?\",\n",
    "    \"こんにちは、今日の調子はどうですか？\",\n",
    "    \"안녕하세요, 오늘 어떻게 지내세요?\",\n",
    "    \"你好，今天怎么样？\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;1m✘ No compatible package found for 'fr_core_web_md' (spaCy v3.8.4)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "import spacy\n",
    "\n",
    "spacy.cli.download(\"fr_core_web_md\")\n",
    "nlp = spacy.load(\"fr_core_web_md\")\n",
    "\n",
    "textes = [\n",
    "    \"Bonjour, comment ca va aujord'hui?\",\n",
    "    \"Hello, how are you today?\",\n",
    "    \"Hallo, wie geht es dir heute?\",\n",
    "    \"Hola, como estas hoy?\",\n",
    "    \"Ciao, come stai oggi?\",\n",
    "    \"Saluton, kiel vi fartas hodiaŭ?\",\n",
    "    \"Hej, hur mår du idag?\",\n",
    "    \"こんにちは、今日の調子はどうですか？\",\n",
    "    \"안녕하세요, 오늘 어떻게 지내세요?\",\n",
    "    \"你好，今天怎么样？\",\n",
    "]\n",
    "\n",
    "def detecter_langue(texte):\n",
    "    try:\n",
    "        langue = detect(texte)\n",
    "        doc = nlp(texte)\n",
    "        tokens = [token.text for token in doc if not token.is_stop]\n",
    "        return langue, tokens\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la détection de la langue: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "for texte in textes:\n",
    "    langue_detectee, tokens_sans_stopwords = detecter_langue(texte)\n",
    "    print(f\"Texte: {texte}\")\n",
    "    print(f\"Langue détectée: {langue_detectee}\")\n",
    "    print(f\"Tokens sans stopwords: {tokens_sans_stopwords}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
